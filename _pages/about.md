---
permalink: /
#title: "Erwan Le Merrer"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am on a researcher position at Inria, in the [WIDE team](https://team.inria.fr/wide/team/). 

>"Maybe, not content to be alienated by observation, maybe does the
>object deceive us? Maybe it invented original answers, and not only
>the ones we ask for? May not be does it not want to be analyzed and
>observed at all and taking this for a challenge (which is true), does
>it respond with another challenge? [...] the object analyzed today
>triumphs everywhere, by its object position, over the subject of analysis."
(Jean Baudrillard, Fatal Strategies.)

My main current research activity is trying to disprove that quote, by studying [black-box algorithms](https://github.com/erwanlemerrer/blackbox-algorithms) in the context of recommender systems, neural-network models, or decision-making algorithms in general. I co-organized with Gilles and Antoine the workshop ["Algorithmes en Boite-Noire"](http://atelier-blackbox.conf.citi-lab.fr/), in a continuous attempt to link several research domains on this societal question.


### Background

I was a senior research scientist at Technicolor R&I (2009-2018), where I worked on scalable storage, processing and machine learning for data analytics. I own a PhD on distributed systems from University of Rennes 1, and a background on peer-to-peer systems, and graph mining/algorithms. My Ph.D. thesis was financed by Orange Labs (where I stayed btw 2004-2007). I obtained my habilitation (HDR) on November 2016 from University of Rennes 1. I am the president and sysadmin of the gozdata association, that provides the gozmail service, built from free software. I am a board member of the [Société Informatique de France](https://www.societe-informatique-de-france.fr/).


### News

* I am co-chair of Eurosys workshops in Rennes in 2022.
* Article ["Le problème du videur : la crédibilité des explications de l’IA en question"](https://interstices.info/le-probleme-du-videur-la-credibilite-des-explications-de-lia-en-question/) on interstices.info.
* I am the PI of the Audita associate team, btw EPFL (SaCS team) and Inria (WIDE), starting in 2021.
* I am at the scientific board of [REGALIA](https://www.inria.fr/fr/le-projet-pilote-regalia-au-service-de-la-regulation-des-algorithmes).
* Paper accepted in CVPR 2021: _SurFree: a fast surrogate-free black-box attack_, presenting a fast (in number of queries) attack to find adversial examples.
* Paper accepted in INFOCOM 2021:  _Setting the Record Straighter on Shadow Banning_, about the shadow banning practices in Twitter.
  * Launched the [whosban.eu.org](https://whosban.eu.org) website, to check how shadow banned you are on Twitter.
  * Paper cited as an evidence in a question to the European parliament ["Censorship and free market restrictions including shadow banning and concealment or suppression of organic search results on internet"](https://www.europarl.europa.eu/doceo/document/E-9-2021-001037_EN.html).
* Related to our black-box observations of YouTube recommendations
  * (short) press: [Comment reprendre le contrôle sur l’algo : des tips utilisateurs à l’utopie algorithmique](https://ctrlzmag.com/comment-reprendre-le-controle-sur-lalgo-des-tips-utilisateurs-a-lutopie-algorithmique/) 
* New article in Nature Machine Intelligence, do not trust remote AI explanations... [[Article link]](https://rdcu.be/b6qB4)
  * pres: ["Le problème du videur : la crédibilité des explications de l’IA en question"](https://interstices.info/le-probleme-du-videur-la-credibilite-des-explications-de-lia-en-question/) sur interstices.info.
  * press: [Do explanations for data-based predictions actually increase users' trust in AI?](https://techxplore.com/news/2020-10-explanations-data-based-users-ai.html) Tech Xplore. Rebranded in [Techhq](https://techhq.com/2020/10/how-much-should-we-trust-explainable-ai/).
  * press: [De l’explicabilité des systèmes : les enjeux de l’explication des décisions automatisées](http://www.internetactu.net/2019/11/14/de-lexplicabilite-des-systemes-les-enjeux-de-lexplication-des-decisions-automatisees/) internetactu.net.
  * press: [Explainable AI” doesn’t work for online services – now there’s proof](https://algorithmwatch.org/en/story/explainable-ai-doesnt-work-for-online-services-now-theres-proof/) Algorithm Watch.
  * press: [It’s Too Easy to Hide Bias in Deep-Learning Systems](https://spectrum.ieee.org/its-too-easy-to-hide-bias-in-deeplearning-systems) IEEE spectrum.
* Juin 2020: participation à la task force "Régulation des GAFA / Transparence et audit des algorithmes" auprès de la Direction Générale des Entreprises (DGE).
* Semestre [Supervision de systèmes dynamiques](https://semestres-cyber.inria.fr/supsec/).
* Feb 2020: joined the board of the [*Société Informatique de France*](https://www.societe-informatique-de-france.fr/).


### Recent publications

* _SurFree: a fast surrogate-free black-box attack_,
Thibault Maho, Teddy Furon, Erwan Le Merrer.
In CVPR (2021). Preprint [[Arxiv 2020]](https://arxiv.org/abs/2011.12807), [[code]](https://github.com/t-maho/SurFree).

* _RoBIC: A benchmark suite for assessing classifiers robustness_,
Thibault Maho, Benoît Bonnet, Teddy Furon, Erwan Le Merrer.
In ICIP (2021) Preprint [[Arxiv 2021]](https://arxiv.org/abs/2102.05368), [[code]](https://gitlab.inria.fr/tmaho/robustness_benchmark).

* _Setting the Record Straighter on Shadow Banning_,
Erwan Le Merrer, Benoît Morgan, Gilles Trédan.
In INFOCOM (2021). [[IEEE link]](https://ieeexplore.ieee.org/document/9488792) [[ArXiv preprint 2020]](https://arxiv.org/abs/2012.05101).
  * press: [Exploring the underpinnings of shadowbanning on Twitter](https://techxplore.com/news/2021-01-exploring-underpinnings-shadowbanning-twitter.html) TechXplore.

* _Remote Explainability faces the bouncer problem_,
Erwan Le Merrer, Gilles Trédan.
In Nature Machine Intelligence (2020). [Paper PDF](https://raw.githubusercontent.com/erwanlemerrer/erwanlemerrer.github.io/master/files/LeMerrer_et_al-2020-Nature_Machine_Intelligence.pdf) [doi](https://doi.org/10.1038/s42256-020-0216-z) [[citation]](https://github.com/erwanlemerrer/erwanlemerrer.github.io/blob/master/files/citations/LMT20-nat.bib).

* _FeGAN: Scaling Distributed GANs_,
Rachid Guerraoui, Arsany Guirguis, Anne-Marie Kermarrec, Erwan Le Merrer.
In Middleware, 2020. [[Preprint]](https://github.com/erwanlemerrer/erwanlemerrer.github.io/raw/master/files/middleware2020-GGKLM-FeGAN-preprint.pdf), [[Presentation video]](https://www.youtube.com/watch?v=s019aDblkDQ).

* _The Imitation Game: Algorithm Selection by Exploiting Black-Box Recommenders_,
Georgios Damaskinos, Rachid Guerraoui, Erwan Le Merrer and Christoph Neumann.
In NETYS, 2020. [[Preprint]](https://github.com/erwanlemerrer/erwanlemerrer.github.io/blob/master/files/imitation_blackbox_recommenders_netys-2020.pdf).

* _zoNNscan : a boundary-entropy index for zone inspection of neural models_,
Adel Jaouen, Erwan Le Merrer.
In Monte Carlo Search workshop (MCS) @ IJCAI 2020 [[ArXiv preprint 2018]](https://arxiv.org/abs/1808.06797).

* _Adversarial Frontier Stitching for Remote Neural Network Watermarking_,
Erwan Le Merrer, Patrick Perez, Gilles Trédan.
In Neural Comput & Applic 32, 9233–9244 (2020). [[editor]](https://link.springer.com/article/10.1007/s00521-019-04434-z)  [[preprint]](https://arxiv.org/abs/1711.01894) [[citation]](https://link.springer.com/article/10.1007/s00521-019-04434-z.ris) 


*Profile photo © Inria / Photo B. Fourrier*

   [.](https://annuel.framapad.org/p/erwan-wishlist-livres)
